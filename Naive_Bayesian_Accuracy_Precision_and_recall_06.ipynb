{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ef914c6-a879-4618-9916-29032d5168e7",
   "metadata": {},
   "source": [
    "# **Assuming a set of documents that need to be classified, use the na√Øve Bayesian Classifier model to perform this task. Built-in Java classes/API can be used to write theprogram. Calculate the accuracy, precision, and recall for your data set.** #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7235906-4867-455f-b626-84303a19f22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the training dataset:  5\n",
      "Dimensions of word counts:  (11314, 130107)\n",
      "Dimensions of TF-IDF matrix:  (11314, 130107)\n",
      "Predicted Accuracy: 77.39%\n",
      "Accuracy:  0.7738980350504514\n",
      "Precision:  [0.80193237 0.81028939 0.81904762 0.67180617 0.85632184 0.88955224\n",
      " 0.93127148 0.84651163 0.93686869 0.92248062 0.89170507 0.59379845\n",
      " 0.83629893 0.92113565 0.84172662 0.43896976 0.64339623 0.92972973\n",
      " 0.95555556 0.97222222]\n",
      "Recall:  [0.52037618 0.64781491 0.65482234 0.77806122 0.77402597 0.75443038\n",
      " 0.69487179 0.91919192 0.9321608  0.89924433 0.96992481 0.96717172\n",
      " 0.59796438 0.73737374 0.89086294 0.98492462 0.93681319 0.91489362\n",
      " 0.41612903 0.13944223]\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.52      0.63       319\n",
      "           comp.graphics       0.81      0.65      0.72       389\n",
      " comp.os.ms-windows.misc       0.82      0.65      0.73       394\n",
      "comp.sys.ibm.pc.hardware       0.67      0.78      0.72       392\n",
      "   comp.sys.mac.hardware       0.86      0.77      0.81       385\n",
      "          comp.windows.x       0.89      0.75      0.82       395\n",
      "            misc.forsale       0.93      0.69      0.80       390\n",
      "               rec.autos       0.85      0.92      0.88       396\n",
      "         rec.motorcycles       0.94      0.93      0.93       398\n",
      "      rec.sport.baseball       0.92      0.90      0.91       397\n",
      "        rec.sport.hockey       0.89      0.97      0.93       399\n",
      "               sci.crypt       0.59      0.97      0.74       396\n",
      "         sci.electronics       0.84      0.60      0.70       393\n",
      "                 sci.med       0.92      0.74      0.82       396\n",
      "               sci.space       0.84      0.89      0.87       394\n",
      "  soc.religion.christian       0.44      0.98      0.61       398\n",
      "      talk.politics.guns       0.64      0.94      0.76       364\n",
      "   talk.politics.mideast       0.93      0.91      0.92       376\n",
      "      talk.politics.misc       0.96      0.42      0.58       310\n",
      "      talk.religion.misc       0.97      0.14      0.24       251\n",
      "\n",
      "                accuracy                           0.77      7532\n",
      "               macro avg       0.83      0.76      0.76      7532\n",
      "            weighted avg       0.82      0.77      0.77      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load the 20 newsgroups dataset for training\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)\n",
    "print(\"Length of the training dataset: \", len(twenty_train))\n",
    "\n",
    "# 2. Extract features from text using CountVectorizer (word counts)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "print('Dimensions of word counts: ', X_train_counts.shape)\n",
    "\n",
    "# 3. Transform word counts into TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "print('Dimensions of TF-IDF matrix: ', X_train_tfidf.shape)\n",
    "\n",
    "# 4. Train a Naive Bayes classifier on the training data\n",
    "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)\n",
    "\n",
    "# 5. Build a pipeline for vectorization, transformation, and classification\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),           # Step 1: CountVectorizer\n",
    "    ('tfidf', TfidfTransformer()),         # Step 2: TfidfTransformer\n",
    "    ('clf', MultinomialNB())               # Step 3: Naive Bayes Classifier\n",
    "])\n",
    "\n",
    "# Train the pipeline on the training data\n",
    "text_clf = text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "# 6. Load the 20 newsgroups dataset for testing\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "\n",
    "# 7. Make predictions on the test data\n",
    "predicted = text_clf.predict(twenty_test.data)\n",
    "\n",
    "# 8. Calculate the prediction accuracy\n",
    "accuracy = np.mean(predicted == twenty_test.target)\n",
    "print(\"Predicted Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# 9. Performance metrics: Accuracy, Precision, Recall, and F1-score\n",
    "print(\"Accuracy: \", metrics.accuracy_score(twenty_test.target, predicted))\n",
    "print(\"Precision: \", metrics.precision_score(twenty_test.target, predicted, average=None))\n",
    "print(\"Recall: \", metrics.recall_score(twenty_test.target, predicted, average=None))\n",
    "\n",
    "# 10. Full classification report\n",
    "print(metrics.classification_report(twenty_test.target, predicted, target_names=twenty_test.target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8728c173-369f-43d2-afaa-839da437d2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
